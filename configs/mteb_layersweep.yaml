run:
  # If null/empty, the CLI will generate a timestamped run_id.
  run_id: null
  output_root: "runs"
  seed: 42

hf:
  # HuggingFace org/repo pattern: {org}/pythia-{size}
  org: "EleutherAI"
  model_family: "Pythia"
  model_sizes: ["14m", "70m", "410m"]
  # Multiple checkpoints for time-layer plane search (checkpoint × layer pairs)
  # 
  # ✅ Pythia models have 154 intermediate checkpoints per model
  # ✅ All model sizes trained on same data, same order → same checkpoints available
  # ✅ Checkpoints hosted on HuggingFace as branches (step{NUMBER} format, no hyphen!)
  #    Example: step0, step1, step1000, step2000, step143000, main
  #
  # IMPORTANT: The bandit workflow has TWO phases:
  #   1. INEXPENSIVE: Compute representation metrics for ALL (checkpoint, layer) pairs
  #      - These metrics serve as features for the bandit
  #      - Cost: Embedding extraction + metric computation (relatively cheap)
  #   2. EXPENSIVE: Bandit intelligently selects which arms to evaluate on downstream tasks
  #      - Uses metrics to predict promising arms
  #      - Only evaluates a small budget-limited subset
  #      - Cost: Full MTEB evaluation (32 tasks) - expensive!
  #
  # The bandit will explore the FULL search space defined here, using metrics to guide
  # which checkpoint-layer pairs to actually evaluate. Don't pre-select - let the bandit decide!
  #
  # "main" = final checkpoint. step{NUMBER} are intermediate training checkpoints.
  #
  # Generate checkpoint lists:
  #   python scripts/generate_pythia_checkpoint_list.py --strategy dense --interval 1000  # Every 1000 steps (~155 checkpoints)
  #   python scripts/generate_pythia_checkpoint_list.py --strategy uniform --interval 2000  # Every 2000 steps (~72 checkpoints)
  #   python scripts/generate_pythia_checkpoint_list.py --strategy log  # Logarithmic sampling (~20 checkpoints)
  #
  # The code will skip unavailable checkpoints with warnings.
  #
  # Recommended: Use dense sampling (every 1000-2000 steps) to give bandit full exploration space
  # Dense sampling (every 1000 steps) - gives bandit full space to explore:
  revisions: ["step0", "step1", "step2", "step4", "step8", "step16", "step32", "step64", "step128", "step256", "step512", "step1000", "step2000", "step3000", "step4000", "step5000", "step6000", "step7000", "step8000", "step9000", "step10000", "step11000", "step12000", "step13000", "step14000", "step15000", "step16000", "step17000", "step18000", "step19000", "step20000", "step21000", "step22000", "step23000", "step24000", "step25000", "step26000", "step27000", "step28000", "step29000", "step30000", "step31000", "step32000", "step33000", "step34000", "step35000", "step36000", "step37000", "step38000", "step39000", "step40000", "step41000", "step42000", "step43000", "step44000", "step45000", "step46000", "step47000", "step48000", "step49000", "step50000", "step51000", "step52000", "step53000", "step54000", "step55000", "step56000", "step57000", "step58000", "step59000", "step60000", "step61000", "step62000", "step63000", "step64000", "step65000", "step66000", "step67000", "step68000", "step69000", "step70000", "step71000", "step72000", "step73000", "step74000", "step75000", "step76000", "step77000", "step78000", "step79000", "step80000", "step81000", "step82000", "step83000", "step84000", "step85000", "step86000", "step87000", "step88000", "step89000", "step90000", "step91000", "step92000", "step93000", "step94000", "step95000", "step96000", "step97000", "step98000", "step99000", "step100000", "step101000", "step102000", "step103000", "step104000", "step105000", "step106000", "step107000", "step108000", "step109000", "step110000", "step111000", "step112000", "step113000", "step114000", "step115000", "step116000", "step117000", "step118000", "step119000", "step120000", "step121000", "step122000", "step123000", "step124000", "step125000", "step126000", "step127000", "step128000", "step129000", "step130000", "step131000", "step132000", "step133000", "step134000", "step135000", "step136000", "step137000", "step138000", "step139000", "step140000", "step141000", "step142000", "step143000", "main"]

embedding:
  pooling: "mean"         # mean pooling over non-padding tokens
  normalize: true         # L2 normalize embeddings
  max_length: 256
  batch_size: 64          # reduce if you hit OOM on GPU
  device: "cuda"          # "auto" | "cuda" | "cpu"
  dtype: "auto"           # "auto" | "float32" | "float16" | "bfloat16"
  # Evaluate all transformer block outputs: layers 0..num_hidden_layers-1
  layers: "all"

mteb:
  # The 32 tasks listed in Table 1 of the Layer-by-Layer paper.
  tasks_preset: "layer_by_layer_32"
  # If you want to override: set tasks: [ ... ] and tasks_preset: null
  tasks: null

execution:
  fail_fast: false
  # If true, skip tasks that already have done.json markers (default true).
  resume: true

# Bandit workflow configuration (optional)
# Set bandit.enabled: true to use bandit-based workflow instead of brute-force sweep
bandit:
  enabled: true  # Set to true to enable bandit workflow
  algorithm: "linUCB"  # Bandit algorithm (currently only linUCB supported)
  alpha: 1.0  # Exploration parameter (higher = more exploration)
  budget: 100  # Number of (checkpoint, layer, task) evaluations
  baseline_checkpoint: "main"  # Checkpoint to use for z-scoring baseline

# Metrics configuration (for bandit workflow)
metrics:
  # Maximum examples per task for representation corpus (None = use all)
  corpus_max_examples_per_task: null
  # Optional path to cache representation corpus (None = auto-generate in run_dir/cache/)
  corpus_cache_path: null

# Rewards configuration (for bandit workflow)
rewards:
  aggregation_method: "mean"  # How to aggregate rewards across tasks: "mean", "harmonic_mean", "robust_mean"
  baseline_method: "mean"  # How to aggregate baseline scores: "mean", "max", "min"