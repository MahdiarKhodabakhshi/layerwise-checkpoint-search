run:
  run_id: "exp2_final50checkpoints_final4layers"
  output_root: "/scratch/mahdiar/pythia-layer-time-runs/pipeline_layer_by_layer"
  seed: 42

hf:
  org: "EleutherAI"
  model_family: "Pythia"
  model_sizes: ["410m"]
  # Final 50 checkpoints (step94000 through step143000)
  revisions: ["step94000", "step95000", "step96000", "step97000", "step98000", "step99000", "step100000", "step101000", "step102000", "step103000", "step104000", "step105000", "step106000", "step107000", "step108000", "step109000", "step110000", "step111000", "step112000", "step113000", "step114000", "step115000", "step116000", "step117000", "step118000", "step119000", "step120000", "step121000", "step122000", "step123000", "step124000", "step125000", "step126000", "step127000", "step128000", "step129000", "step130000", "step131000", "step132000", "step133000", "step134000", "step135000", "step136000", "step137000", "step138000", "step139000", "step140000", "step141000", "step142000", "step143000"]

embedding:
  pooling: "mean"
  normalize: true
  max_length: 256
  batch_size: 64
  device: "cuda"
  dtype: "auto"
  # Final 4 layers of Pythia 410m (has 24 layers: 0-23)
  # Final 4: 20, 21, 22, 23
  layers: "20,21,22,23"

mteb:
  # All 32 MTEB tasks from Table 1 of the paper
  tasks_preset: "layer_by_layer_32"
  tasks: null

execution:
  fail_fast: false
  resume: true

# Bandit workflow disabled - brute-force evaluation
bandit:
  enabled: false

metrics:
  corpus_max_examples_per_task: null
  corpus_cache_path: null

rewards:
  aggregation_method: "mean"
  baseline_method: "mean"
